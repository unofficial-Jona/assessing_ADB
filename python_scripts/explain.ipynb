{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/workspace/persistent/thesis/OadTR\")\n",
    "\n",
    "import os\n",
    "import xmltodict\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import json\n",
    "\n",
    "from glob import glob\n",
    "from zipfile import ZipFile\n",
    "from pdb import set_trace\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision.io import read_video\n",
    "from torchvision.utils import flow_to_image\n",
    "from torchvision.models import resnet50, ResNet50_Weights\n",
    "from torchvision.models.optical_flow import raft_large, Raft_Large_Weights\n",
    "from torchvision.models.feature_extraction import create_feature_extractor\n",
    "\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import matplotlib.lines as mlines\n",
    "\n",
    "\n",
    "\n",
    "from custom_utils import get_args, load_model_and_checkpoint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bbx_coordinates(zip_path):\n",
    "    \"\"\"\n",
    "    return list of tensors.\n",
    "    one tensor for each agent in frame ('track' in xml_file). \n",
    "    Each tensor is initialized as (nr_frames, 4). \n",
    "    Each entry at dimension 1 represents a coordinate of a bounding box. (xtl, ytl, xbr, ybr)\n",
    "    \"\"\"\n",
    "    out_dict = dict()\n",
    "\n",
    "    zip_file = ZipFile(zip_path)\n",
    "\n",
    "    xml_file = xmltodict.parse(zip_file.read('annotations.xml'))['annotations']\n",
    "\n",
    "    # get index from stop_frame\n",
    "    last_frame = int(xml_file['meta']['task']['stop_frame'])\n",
    "\n",
    "    if not isinstance(xml_file['track'], list):\n",
    "        xml_file['track'] = [xml_file['track']]\n",
    "\n",
    "    for track in xml_file['track']:\n",
    "        actor_id = track['@id']\n",
    "        actor_name = track['@label']\n",
    "        if actor_name not in ['Car', 'MotorBike', 'Scooter']:\n",
    "            continue\n",
    "        track_tensor = torch.zeros((last_frame + 1, 4))\n",
    "        for box in track['box']:\n",
    "            frame_index = box['@frame']\n",
    "            xtl = box['@xtl']\n",
    "            ytl = box['@ytl']\n",
    "            xbr = box['@xbr']\n",
    "            ybr = box['@ybr']\n",
    "\n",
    "            for i, coordinate in zip(range(4), [xtl, ytl, xbr, ybr]):\n",
    "                track_tensor[int(frame_index), i] = float(coordinate)\n",
    "\n",
    "        out_dict.update({actor_id:{'name':actor_name, 'bbx':track_tensor}})\n",
    "    return out_dict\n",
    "\n",
    "def coordinates_to_masks(frames_shape, coordinates):\n",
    "    \"\"\"\n",
    "    utility function to convert tensor of shape (t, 4) to mask\n",
    "    frames_shape: touple of ints, representing TCHW format\n",
    "    \n",
    "    returned masks are 0 in bounding box and 1 everywhere else (positive mask)\n",
    "    \"\"\"\n",
    "    mask = torch.ones(frames_shape)\n",
    "\n",
    "    for t, (xtl, ytl, xbr, ybr) in enumerate(coordinates):\n",
    "        # Convert bounding box coordinates to integers\n",
    "        xtl, ytl, xbr, ybr = map(int, [xtl, ytl, xbr, ybr])\n",
    "\n",
    "        # Set the area inside the bounding box to 0\n",
    "        mask[t, :, ytl:ybr, xtl:xbr] = 0\n",
    "\n",
    "    return mask\n",
    "\n",
    "def check_mask_for_bbx(mask):\n",
    "    \"\"\"\n",
    "    utility function to check whether there is an actual bounding box within the mask.\n",
    "    can be used to determine if mask can be omited.\n",
    "    Check if mask is all ones or all zeros. In both cases return True\n",
    "    \"\"\"\n",
    "    mask = mask.to(bool)\n",
    "    return torch.all(mask) or torch.all(~mask)\n",
    "\n",
    "def apply_mask(frames, mask, pos=True):\n",
    "    \"\"\"\n",
    "    utility function to apply mask tensor to frames tensor.\n",
    "    \"\"\"\n",
    "    assert frames.shape == mask.shape, 'frames and masks have different shapes'\n",
    "\n",
    "    # invert mask if pos=False\n",
    "    if pos == False:\n",
    "        mask = ~mask.to(bool)\n",
    "\n",
    "    # apply mask\n",
    "    frames = frames * mask\n",
    "    return frames\n",
    "\n",
    "def reduce_framerate(frames, target_fps=15, source_fps = 30):\n",
    "    assert source_fps % target_fps == 0, \"Target FPS must be a divisor of the source FPS\"\n",
    "\n",
    "    frame_skip = int(source_fps / target_fps)\n",
    "    reduced_fps_video = frames[::frame_skip]\n",
    "    return reduced_fps_video\n",
    "\n",
    "def get_agent_frames(video_name, frame_level_features=True, start_frame=65, length=64, **kwargs):\n",
    "    if frame_level_features:\n",
    "        length += 1\n",
    "    \n",
    "    # define paths to original videos\n",
    "    ANNO_DIR = kwargs.get('anno_dir', '/workspace/pvc-meteor/downloads/Video XML Annotations/')\n",
    "    VID_DIR = kwargs.get('vid_dir', '/workspace/pvc-meteor/Raw_Videos/')\n",
    "    positive_mask = kwargs.get('pos', True)\n",
    "    target_fps = kwargs.get('FPS', 15)\n",
    "    \n",
    "    zip_loc = os.path.join(ANNO_DIR, video_name[:-4] + '.zip')\n",
    "    video_loc = os.path.join(VID_DIR, video_name)\n",
    "    \n",
    "    # load coordinates\n",
    "    # {actor_id:{'name':actor_name, 'bbx':track_tensor}}\n",
    "    coordinates = get_bbx_coordinates(zip_loc)\n",
    "    \n",
    "    # load frames\n",
    "    frames, _, _ = read_video(video_loc, pts_unit='sec', output_format='TCHW')\n",
    "    org_frames_shape = frames.shape\n",
    "    # apply FPS change to video\n",
    "    frames = reduce_framerate(frames, target_fps = target_fps)[start_frame - length:start_frame]\n",
    "    \n",
    "    # prepare dictionary to handle agent_id, name and masked video\n",
    "    agent_dict = dict()\n",
    "    # save original frames for comparison\n",
    "    coordinates.update({'-1':{'name':'orig', 'masked_frames': frames}})\n",
    "    # agent_dict.update({'-1':{'name':'orig', 'masked_frames': frames}})\n",
    "    # for agent in video: \n",
    "    for k, v in coordinates.items():        \n",
    "        if not 'bbx' in v.keys():\n",
    "            continue\n",
    "        coordinate_tensor = v['bbx']\n",
    "        # reduce FPS of coordinate tensor and cut to correct times\n",
    "        coordinate_tensor = reduce_framerate(coordinate_tensor, target_fps = target_fps)[start_frame - length:start_frame]\n",
    "\n",
    "        # save reduced bbx tensor instead of the old one\n",
    "        v.update({'bbx': coordinate_tensor})\n",
    "\n",
    "        # generate mask\n",
    "        mask = coordinates_to_masks(frames.shape, coordinate_tensor)\n",
    "\n",
    "        # if mask is all 1s, there is no bbx --> \n",
    "        if check_mask_for_bbx(mask):\n",
    "            continue\n",
    "        \n",
    "        agent_frames = apply_mask(frames, mask, pos=positive_mask)\n",
    "\n",
    "        coordinates[k].update({'masked_frames':agent_frames})\n",
    "        # agent_dict.update({k:{'name':v['name'], 'masked_frames':agent_frames}})\n",
    "    return coordinates\n",
    "\n",
    "def get_conv_features(agent_dict, **kwargs):\n",
    "    device = kwargs.get('device', 'cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    rgb_extractor = create_feature_extractor(resnet50(weights = ResNet50_Weights.DEFAULT, progress=False), return_nodes={'flatten': 'flatten'}).eval().to(device)\n",
    "    flow_extractor = raft_large(weights = Raft_Large_Weights.DEFAULT, progress=False).eval().to(device)\n",
    "\n",
    "    # disable gradients to reduce memory footprint\n",
    "    for model in [rgb_extractor, flow_extractor]:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "    feature_dict = dict()\n",
    "\n",
    "    for k, v in agent_dict.items():\n",
    "        if 'masked_frames' not in v.keys():\n",
    "            continue\n",
    "        assert v['masked_frames'].shape[0] == 64 + 1, 'wrong number of frames'\n",
    "        frames = (v['masked_frames']/255).to(device)\n",
    "\n",
    "        flow_stack_1 = frames[:-1]\n",
    "        flow_stack_2 = frames[1:]\n",
    "\n",
    "        rgb_transforms = ResNet50_Weights.DEFAULT.transforms()\n",
    "        flow_transforms = Raft_Large_Weights.DEFAULT.transforms()\n",
    "\n",
    "        rgb_features = rgb_extractor(rgb_transforms(flow_stack_2))['flatten']\n",
    "        rgb_features = rgb_features.detach().cpu().numpy()\n",
    "\n",
    "        flow_estimate = flow_extractor(rgb_transforms(flow_stack_1), rgb_transforms(flow_stack_2))\n",
    "\n",
    "        flow_img = flow_to_image(flow_estimate[-1])\n",
    "\n",
    "        flow_features = rgb_extractor(rgb_transforms(flow_img))['flatten']\n",
    "        flow_features = flow_features.detach().cpu().numpy()\n",
    "\n",
    "\n",
    "        agent_dict[k].update({'rgb_features':rgb_features, 'flow_features':flow_features})\n",
    "        # feature_dict.update({k: {'name':v['name'], 'rgb_features':rgb_features, 'flow_features':flow_features}})\n",
    "    \n",
    "    return agent_dict\n",
    "\n",
    "\n",
    "def get_predictions_from_model(feature_dict, model, **kwargs):\n",
    "    device = kwargs.get('device', 'cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = model.eval().to(device)\n",
    "    for k,v in  feature_dict.items():\n",
    "        if 'masked_frames' not in v.keys():\n",
    "            continue\n",
    "        rgb_features = torch.from_numpy(v['rgb_features']).to(device)\n",
    "        flow_features = torch.from_numpy(v['flow_features']).to(device)\n",
    "        out = model(rgb_features.unsqueeze(0), flow_features.unsqueeze(0))\n",
    "        # use first element of tuple output (represents final classification score)\n",
    "        out = out[0]\n",
    "        # transform values into range [0,1]\n",
    "        out = torch.sigmoid(out)\n",
    "        out = out.detach().cpu().numpy()\n",
    "        feature_dict[k].update({'prediction':out})\n",
    "    return feature_dict\n",
    "\n",
    "\n",
    "def get_prediction_differences(prediction_dict):\n",
    "    orig_predict = prediction_dict['-1']['prediction']\n",
    "    for k, v in prediction_dict.items():\n",
    "        # only agents that are in the scene\n",
    "        if 'prediction' not in v.keys():\n",
    "            continue\n",
    "        \n",
    "        agent_predict = v['prediction']\n",
    "        pred_dif = orig_predict - agent_predict\n",
    "        prediction_dict[k].update({'prediction_dif':pred_dif})\n",
    "    return prediction_dict\n",
    "\n",
    "def visualise_last_frame(prediction_dict, save_path=None):\n",
    "    last_frame = prediction_dict['-1']['masked_frames'][-1]\n",
    "    \n",
    "    assert last_frame.shape[0] == 3, \"didn't pick last frame\"\n",
    "    \n",
    "    fig, ax = plt.subplots(1)\n",
    "\n",
    "    # Display the image\n",
    "    ax.imshow(last_frame.permute(1,2,0))\n",
    "\n",
    "    # Create a colormap for the bounding boxes\n",
    "    colormap = cm.get_cmap('Set3')\n",
    "    num_bbx = len(prediction_dict.keys()) - 1  # subtract 1 because we're excluding '-1'\n",
    "    colors = [colormap(i) for i in np.linspace(0, 1, num_bbx)]\n",
    "\n",
    "    legend_handles = []\n",
    "    color_index = 0\n",
    "\n",
    "    for k, v in prediction_dict.items():\n",
    "        # ignore if agent is not in scene, not in last frame, or entry corresponds to original video\n",
    "        if 'prediction' not in v.keys() or k == '-1' or v['bbx'][-1].sum() == 0:\n",
    "            continue\n",
    "        \n",
    "        color = colors[color_index]\n",
    "\n",
    "        # retrieve coordinates for rectangle\n",
    "        xtl, ytl, xbr, ybr = v['bbx'][-1]\n",
    "\n",
    "        # draw rectangle using these coordinates\n",
    "        rect = patches.Rectangle((xtl, ytl), xbr-xtl, ybr-ytl, linewidth=1, edgecolor=color, facecolor='none')\n",
    "        ax.add_patch(rect)\n",
    "\n",
    "        # write prediction differences above bounding box\n",
    "        pred_diff_str = ', '.join(map(str, np.round(v['prediction_dif'].squeeze()[1:],3).tolist()))\n",
    "        legend_handle = mlines.Line2D([], [], color=color, marker='o', markersize=15, label=pred_diff_str)\n",
    "        legend_handles.append(legend_handle)\n",
    "\n",
    "        color_index += 1  # move to the next color for the next bounding box\n",
    "\n",
    "    # Create the legend\n",
    "    ax.legend(handles=legend_handles, bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "    # Save the figure if a path is specified\n",
    "    if save_path is not None:\n",
    "        plt.savefig(save_path, bbox_inches='tight')  # use bbox_inches to include the legend in the saved image\n",
    "    else:\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "def check_video_for_interesting_frames(vid_name, **kwargs):\n",
    "    out_dict = {'LaneChanging':{}, 'LaneChanging(m)':{}, 'OverTaking':{}, 'Cutting':{}, 'RuleBreak':{}}\n",
    "    ANNO_DIR = kwargs.get('anno_dir', '/workspace/pvc-meteor/downloads/Video XML Annotations/')\n",
    "    VID_DIR = kwargs.get('vid_dir', '/workspace/pvc-meteor/Raw_Videos/')\n",
    "    ATTRIBUTES = ['LaneChanging', 'LaneChanging(m)', 'OverTaking', 'Cutting', 'RuleBreak']\n",
    "    VALUES = ['True', 'true', 'WrongLane']\n",
    "    first_reasonable_frame = kwargs.get('first_frame', 65)\n",
    "    \n",
    "    zip_name = vid_name[:-4] + '.zip' if vid_name.endswith('.MP4') else vid_name\n",
    "    \n",
    "    if not vid_name.startswith(ANNO_DIR):\n",
    "        zip_path = os.path.join(ANNO_DIR, zip_name)\n",
    "\n",
    "    zip_file = ZipFile(zip_path)\n",
    "\n",
    "    xml_file = xmltodict.parse(zip_file.read('annotations.xml'))['annotations']\n",
    "\n",
    "    if not isinstance(xml_file['track'], list):\n",
    "        xml_file['track'] = [xml_file['track']]\n",
    "\n",
    "    for track in xml_file['track']:\n",
    "        actor_name = track['@label']\n",
    "        if actor_name not in ['Car', 'MotorBike', 'Scooter']:\n",
    "            continue\n",
    "        for box in track['box']:\n",
    "            frame = box['@frame']\n",
    "            for attribute in box['attribute']:\n",
    "                if attribute['@name'] in ATTRIBUTES and attribute['#text'] in VALUES:\n",
    "                    if vid_name not in out_dict[attribute['@name']].keys():\n",
    "                        out_dict[attribute['@name']].update({vid_name:[frame]})\n",
    "                    else:\n",
    "                        out_dict[attribute['@name']][vid_name].append(frame)\n",
    "\n",
    "    # First, merge 'LaneChanging(m)' into 'LaneChanging'\n",
    "    out_dict['LaneChanging'] = {**out_dict['LaneChanging'], **out_dict['LaneChanging(m)']}\n",
    "    out_dict['WrongLane'] = out_dict['RuleBreak']\n",
    "    # Then, delete the 'LaneChanging(m)' entry\n",
    "    del out_dict['LaneChanging(m)']\n",
    "    del out_dict['RuleBreak']\n",
    "\n",
    "    return out_dict\n",
    "\n",
    "\n",
    "# check_video_for_interesting_frames(TEST_NAME)\n",
    "\n",
    "def search_dir_for_interesting_frames(dir='/workspace/pvc-meteor/Raw_Videos/', save=False):\n",
    "    out_dict = {'LaneChanging':{}, 'OverTaking':{}, 'Cutting':{}, 'WrongLane':{}}\n",
    "    for vid_name in tqdm(os.listdir(dir)):\n",
    "        vid_dict = check_video_for_interesting_frames(vid_name)\n",
    "\n",
    "        for key in out_dict.keys():\n",
    "            out_dict[key].update(vid_dict[key])\n",
    "    \n",
    "    if save:\n",
    "        with open(os.path.join(save, 'interesting_frames.pkl'), 'wb') as f:\n",
    "            pickle.dump(out_dict, f)\n",
    "    \n",
    "    return vid_dict\n",
    "\n",
    "\n",
    "# define files for testing purposes\n",
    "TEST_NAME = 'REC_2020_09_08_04_51_57_F.MP4'\n",
    "MODEL_DIR = '/workspace/persistent/thesis/OadTR/experiments/final/features_conv_15_new.pkl/'\n",
    "\n",
    "agent_dict = get_agent_frames(TEST_NAME)\n",
    "out_features = get_conv_features(agent_dict)\n",
    "\n",
    "args = get_args(MODEL_DIR)\n",
    "model = load_model_and_checkpoint(args, MODEL_DIR)\n",
    "\n",
    "out_dict = get_predictions_from_model(out_features, model)\n",
    "out_dict = get_prediction_differences(out_dict)\n",
    "visualise_last_frame(out_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 32/1251 [01:10<45:00,  2.22s/it]  \n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "string indices must be integers",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[45], line 60\u001b[0m\n\u001b[1;32m     56\u001b[0m             pickle\u001b[39m.\u001b[39mdump(out_dict, f)\n\u001b[1;32m     58\u001b[0m     \u001b[39mreturn\u001b[39;00m vid_dict\n\u001b[0;32m---> 60\u001b[0m search_dir_for_interesting_frames(save\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m/workspace/pvc-meteor/features/\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "Cell \u001b[0;32mIn[45], line 49\u001b[0m, in \u001b[0;36msearch_dir_for_interesting_frames\u001b[0;34m(dir, save)\u001b[0m\n\u001b[1;32m     47\u001b[0m out_dict \u001b[39m=\u001b[39m {\u001b[39m'\u001b[39m\u001b[39mLaneChanging\u001b[39m\u001b[39m'\u001b[39m:{}, \u001b[39m'\u001b[39m\u001b[39mOverTaking\u001b[39m\u001b[39m'\u001b[39m:{}, \u001b[39m'\u001b[39m\u001b[39mCutting\u001b[39m\u001b[39m'\u001b[39m:{}, \u001b[39m'\u001b[39m\u001b[39mWrongLane\u001b[39m\u001b[39m'\u001b[39m:{}}\n\u001b[1;32m     48\u001b[0m \u001b[39mfor\u001b[39;00m vid_name \u001b[39min\u001b[39;00m tqdm(os\u001b[39m.\u001b[39mlistdir(\u001b[39mdir\u001b[39m)):\n\u001b[0;32m---> 49\u001b[0m     vid_dict \u001b[39m=\u001b[39m check_video_for_interesting_frames(vid_name)\n\u001b[1;32m     51\u001b[0m     \u001b[39mfor\u001b[39;00m key \u001b[39min\u001b[39;00m out_dict\u001b[39m.\u001b[39mkeys():\n\u001b[1;32m     52\u001b[0m         out_dict[key]\u001b[39m.\u001b[39mupdate(vid_dict[key])\n",
      "Cell \u001b[0;32mIn[45], line 26\u001b[0m, in \u001b[0;36mcheck_video_for_interesting_frames\u001b[0;34m(vid_name, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[39mcontinue\u001b[39;00m\n\u001b[1;32m     25\u001b[0m \u001b[39mfor\u001b[39;00m box \u001b[39min\u001b[39;00m track[\u001b[39m'\u001b[39m\u001b[39mbox\u001b[39m\u001b[39m'\u001b[39m]:\n\u001b[0;32m---> 26\u001b[0m     frame \u001b[39m=\u001b[39m box[\u001b[39m'\u001b[39;49m\u001b[39m@frame\u001b[39;49m\u001b[39m'\u001b[39;49m]\n\u001b[1;32m     27\u001b[0m     \u001b[39mfor\u001b[39;00m attribute \u001b[39min\u001b[39;00m box[\u001b[39m'\u001b[39m\u001b[39mattribute\u001b[39m\u001b[39m'\u001b[39m]:\n\u001b[1;32m     28\u001b[0m         \u001b[39mif\u001b[39;00m attribute[\u001b[39m'\u001b[39m\u001b[39m@name\u001b[39m\u001b[39m'\u001b[39m] \u001b[39min\u001b[39;00m ATTRIBUTES \u001b[39mand\u001b[39;00m attribute[\u001b[39m'\u001b[39m\u001b[39m#text\u001b[39m\u001b[39m'\u001b[39m] \u001b[39min\u001b[39;00m VALUES:\n",
      "\u001b[0;31mTypeError\u001b[0m: string indices must be integers"
     ]
    }
   ],
   "source": [
    "def check_video_for_interesting_frames(vid_name, **kwargs):\n",
    "    out_dict = {'LaneChanging':{}, 'LaneChanging(m)':{}, 'OverTaking':{}, 'Cutting':{}, 'RuleBreak':{}}\n",
    "    ANNO_DIR = kwargs.get('anno_dir', '/workspace/pvc-meteor/downloads/Video XML Annotations/')\n",
    "    VID_DIR = kwargs.get('vid_dir', '/workspace/pvc-meteor/Raw_Videos/')\n",
    "    ATTRIBUTES = ['LaneChanging', 'LaneChanging(m)', 'OverTaking', 'Cutting', 'RuleBreak']\n",
    "    VALUES = ['True', 'true', 'WrongLane']\n",
    "    first_reasonable_frame = kwargs.get('first_frame', 65)\n",
    "    \n",
    "    zip_name = vid_name[:-4] + '.zip' if vid_name.endswith('.MP4') else vid_name\n",
    "    \n",
    "    if not vid_name.startswith(ANNO_DIR):\n",
    "        zip_path = os.path.join(ANNO_DIR, zip_name)\n",
    "\n",
    "    zip_file = ZipFile(zip_path)\n",
    "\n",
    "    xml_file = xmltodict.parse(zip_file.read('annotations.xml'))['annotations']\n",
    "\n",
    "    if not isinstance(xml_file['track'], list):\n",
    "        xml_file['track'] = [xml_file['track']]\n",
    "\n",
    "    for track in xml_file['track']:\n",
    "        actor_name = track['@label']\n",
    "        if actor_name not in ['Car', 'MotorBike', 'Scooter']:\n",
    "            continue\n",
    "        for box in track['box']:\n",
    "            frame = box['@frame']\n",
    "            for attribute in box['attribute']:\n",
    "                if attribute['@name'] in ATTRIBUTES and attribute['#text'] in VALUES:\n",
    "                    if vid_name not in out_dict[attribute['@name']].keys():\n",
    "                        out_dict[attribute['@name']].update({vid_name:[frame]})\n",
    "                    else:\n",
    "                        out_dict[attribute['@name']][vid_name].append(frame)\n",
    "\n",
    "    # First, merge 'LaneChanging(m)' into 'LaneChanging'\n",
    "    out_dict['LaneChanging'] = {**out_dict['LaneChanging'], **out_dict['LaneChanging(m)']}\n",
    "    out_dict['WrongLane'] = out_dict['RuleBreak']\n",
    "    # Then, delete the 'LaneChanging(m)' entry\n",
    "    del out_dict['LaneChanging(m)']\n",
    "    del out_dict['RuleBreak']\n",
    "\n",
    "    return out_dict\n",
    "\n",
    "\n",
    "# check_video_for_interesting_frames(TEST_NAME)\n",
    "\n",
    "def search_dir_for_interesting_frames(dir='/workspace/pvc-meteor/Raw_Videos/', save=False):\n",
    "    out_dict = {'LaneChanging':{}, 'OverTaking':{}, 'Cutting':{}, 'WrongLane':{}}\n",
    "    for vid_name in tqdm(os.listdir(dir)):\n",
    "        vid_dict = check_video_for_interesting_frames(vid_name)\n",
    "\n",
    "        for key in out_dict.keys():\n",
    "            out_dict[key].update(vid_dict[key])\n",
    "    \n",
    "    if save:\n",
    "        with open(os.path.join(save, 'interesting_frames.pkl'), 'wb') as f:\n",
    "            pickle.dump(out_dict, f)\n",
    "    \n",
    "    return vid_dict\n",
    "\n",
    "search_dir_for_interesting_frames(save='/workspace/pvc-meteor/features/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
