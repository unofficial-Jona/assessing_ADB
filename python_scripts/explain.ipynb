{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "import os\n",
    "\n",
    "from glob import glob\n",
    "from zipfile import ZipFile\n",
    "import xmltodict\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "from torchvision.io import read_video\n",
    "import torch\n",
    "\n",
    "# define paths to original videos\n",
    "ANNO_DIR = '/workspace/pvc-meteor/downloads/Video XML Annotations/'\n",
    "VID_DIR = '/workspace/pvc-meteor/Raw_Videos/'\n",
    "\n",
    "# define files for testing purposes\n",
    "TEST_NAME = 'REC_1970_01_01_07_40_16_F.MP4'\n",
    "\n",
    "TEST_VID = os.path.join(VID_DIR, TEST_NAME)\n",
    "TEST_ANNO = os.path.join(ANNO_DIR, TEST_NAME[:-4] + '.zip')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bbx_coordinates(zip_path):\n",
    "    \"\"\"\n",
    "    return list of tensors.\n",
    "    one tensor for each agent in frame ('track' in xml_file). \n",
    "    Each tensor is initialized as (nr_frames, 4). \n",
    "    Each entry at dimension 1 represents a coordinate of a bounding box.\n",
    "    --> if all entries are 0, there is no bounding box, hence no mask later.\n",
    "    else apply mask.\n",
    "    \"\"\"\n",
    "    out_list = list()\n",
    "    zip_file = ZipFile(zip_path)\n",
    "\n",
    "    xml_file = xmltodict.parse(zip_file.read('annotations.xml'))['annotations']\n",
    "\n",
    "    # get index from stop_frame\n",
    "    last_frame = int(xml_file['meta']['task']['stop_frame'])\n",
    "\n",
    "    if not isinstance(xml_file['track'], list):\n",
    "        xml_file['track'] = [xml_file['track']]\n",
    "\n",
    "    for track in xml_file['track']:\n",
    "        track_tensor = torch.zeros((last_frame + 1, 4))\n",
    "        for box in track['box']:\n",
    "            frame_index = box['@frame']\n",
    "            xtl = box['@xtl']\n",
    "            ytl = box['@ytl']\n",
    "            xbr = box['@xbr']\n",
    "            ybr = box['@ybr']\n",
    "\n",
    "            for i, coordinate in zip(range(4), [xtl, ytl, xbr, ybr]):\n",
    "                track_tensor[int(frame_index), i] = float(coordinate)\n",
    "\n",
    "        out_list.append(track_tensor)\n",
    "    return out_list\n",
    "\n",
    "test_bbx_coordinates = get_bbx_coordinates(TEST_ANNO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_pos_masks(vid_name, bbx_coordinates, nr_frames=64, start_frame=0):\n",
    "    \"\"\"\n",
    "    generate masks (binary) from bbx_coordinates (round corner coordinates)\n",
    "    mask is positive --> remove area within bbx_coordinates (set to 0)\n",
    "    return list of masked videos\n",
    "    \"\"\"\n",
    "    frames, _, _ = read_video(vid_name, pts_unit='sec', output_format='TCHW')\n",
    "\n",
    "    out_list = list()\n",
    "\n",
    "    for track in bbx_coordinates:\n",
    "        # Create a mask of the same size as the video\n",
    "        mask = torch.ones_like(frames)\n",
    "        \n",
    "        # Loop over each frame and its corresponding bounding box\n",
    "        for t, (xtl, ytl, xbr, ybr) in enumerate(track):\n",
    "            # Convert bounding box coordinates to integers\n",
    "            xtl, ytl, xbr, ybr = map(int, [xtl, ytl, xbr, ybr])\n",
    "\n",
    "            # Set the area inside the bounding box to 0\n",
    "            mask[t, :, ytl:ybr, xtl:xbr] = 0\n",
    "\n",
    "        # Apply the mask to the video\n",
    "        video_masked = frames * mask\n",
    "\n",
    "        out_list.append(video_masked)\n",
    "    \n",
    "    return out_list\n",
    "\n",
    "tet_pos_mask = apply_pos_masks(TEST_VID, test_bbx_coordinates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 1.],\n",
       "       [1., 0., 1.],\n",
       "       [1., 1., 1.]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.ones((3,3))\n",
    "b = np.ones((3,3))\n",
    "a[1,1] = 0\n",
    "a * b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_pos_masks(vid_name, bbx_coordinates, nr_frames=64, start_frame=0):\n",
    "    \"\"\"\n",
    "    generate masks (binary) from bbx_coordinates (round corner coordinates)\n",
    "    mask is positive --> remove area within bbx_coordinates (set to 0)\n",
    "    return list of masked videos\n",
    "    \"\"\"\n",
    "    frames, _, _ = read_video(vid_name, pts_unit='sec', output_format='TCHW')\n",
    "\n",
    "    out_list = list()\n",
    "\n",
    "    for track in bbx_coordinates:\n",
    "        # Create a mask of the same size as the video\n",
    "        mask = torch.zeros_like(frames)\n",
    "        \n",
    "        # Loop over each frame and its corresponding bounding box\n",
    "        for t, (xtl, ytl, xbr, ybr) in enumerate(bbx_coordinates):\n",
    "            # Convert bounding box coordinates to integers\n",
    "            xtl, ytl, xbr, ybr = map(int, [xtl, ytl, xbr, ybr])\n",
    "\n",
    "            # Set the area inside the bounding box to 0\n",
    "            mask[t, :, ytl:ybr, xtl:xbr] = 1\n",
    "\n",
    "        # Apply the mask to the video\n",
    "        video_masked = video * mask\n",
    "\n",
    "        out_list.append(video_masked)\n",
    "    \n",
    "    return out_list\n",
    "# %%\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
