{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Logger multiprocessing (WARNING)>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torchvision.transforms.functional as TF\n",
    "from torchvision.models.optical_flow import raft_large\n",
    "from torchvision.models.optical_flow import Raft_Large_Weights\n",
    "from torchvision.utils import flow_to_image\n",
    "from torchvision.models.feature_extraction import get_graph_node_names\n",
    "from torchvision.models.feature_extraction import create_feature_extractor\n",
    "from torchvision.models import resnet50, ResNet50_Weights\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "from zipfile import ZipFile\n",
    "import xmltodict\n",
    "import os\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "import gc\n",
    "# import cv2\n",
    "\n",
    "from tqdm import tqdm\n",
    "from tqdm.contrib.concurrent import process_map\n",
    "from torchvision.io import read_video\n",
    "import torch\n",
    "\n",
    "from multiprocessing import cpu_count, Pool, log_to_stderr, Manager\n",
    "# TODO: disable log_to_stderr()\n",
    "log_to_stderr()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureExtractor():\n",
    "    def __init__(self, FPS, **kwargs):\n",
    "        assert FPS in [1, 2, 3, 5, 10, 15, 30], 'for now input musst be perfect divisor of 30 ([1, 2, 3, 5, 10, 15, 30])'\n",
    "\n",
    "        # 30 is the framerate of the METEOR Data,\n",
    "        self.frame_interval = int(30/FPS)\n",
    "        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "        self.resize = kwargs.get('resize', (448,448))\n",
    "    \n",
    "        self.batch_size = kwargs.get('batch_size', 32)\n",
    "\n",
    "        if 'flow_model' in kwargs.keys():\n",
    "            warnings.warn('Using a different flow model may require disabling backprop', category=UserWarning, stacklevel=2)\n",
    "            self.flow_model = kwargs['flow_model']\n",
    "            flow_weights = kwargs['flow_weights']\n",
    "            self.transforms = flow_weights.transforms()\n",
    "\n",
    "        else:\n",
    "            self.flow_model = raft_large(\n",
    "                weights=Raft_Large_Weights.DEFAULT, progress=False).to(self.device)\n",
    "            for param in self.flow_model.parameters():\n",
    "                param.requires_grad = False\n",
    "            flow_weights = Raft_Large_Weights.DEFAULT\n",
    "            self.transforms = flow_weights.transforms()\n",
    "\n",
    "        if 'rgb_model' in kwargs.keys():\n",
    "            self.rgb_model = kwargs['rgb_model']\n",
    "            warnings.warn('Using a different rgb model may require disabling backprop', category=UserWarning, stacklevel=2)\n",
    "        else:\n",
    "            model = resnet50(weights=ResNet50_Weights.DEFAULT, progress=False)\n",
    "            for param in model.parameters():\n",
    "                param.requires_grad = False\n",
    "            self.rgb_model = create_feature_extractor(\n",
    "                model, return_nodes={'flatten': 'flatten'}).to(self.device)\n",
    "\n",
    "        if 'vid_dir' in kwargs.keys():\n",
    "            self.vid_dir = kwargs['vid_dir']\n",
    "        else:\n",
    "            self.vid_dir = '/workspace/pvc-meteor/Raw_Videos/'\n",
    "        if 'anno_zip_dir' in kwargs.keys():\n",
    "            self.anno_zip_dir = kwargs['anno_zip_dir']\n",
    "        else:\n",
    "            self.anno_zip_dir = '/workspace/pvc-meteor/downloads/Frame XML Annotations/'\n",
    "        if 'output_dir' in kwargs.keys():\n",
    "            self.output_dir = kwargs['output_dir']\n",
    "        else:\n",
    "            self.output_dir = '/workspace/pvc-meteor/features/'\n",
    "\n",
    "        if 'labels' in kwargs.keys():\n",
    "            self.labels = kwargs['labels']\n",
    "        else:\n",
    "            self.labels = {'RuleBreak': {'WrongLane', 'WrongTurn', 'TrafficLight'}, 'LaneChanging': {'True'}, 'LaneChanging(m)': {\n",
    "                'True'}, 'OverTaking': {'True'}, 'Yield': {'True'}, 'Cutting': {'True'}, 'ZigzagMovement': {'True'}, 'OverSpeeding': {'True'}}\n",
    "        if 'labels_mapping' in kwargs.keys():\n",
    "            self.labels_mapping = kwargs['labels_mapping']\n",
    "        else:\n",
    "            self.labels_mapping = {'RuleBreak': 0, 'LaneChanging': 1,\n",
    "                                   'LaneChanging(m)': 1, 'OverTaking': 2, 'Yield': 3, 'Cutting': 4, 'ZigzagMovement': 5, 'OverSpeeding': 6}\n",
    "\n",
    "    def video_processor(self, video):\n",
    "        frames, _, _ = read_video(video, pts_unit='sec', output_format='TCHW')\n",
    "\n",
    "        rgb_frames = torch.stack([frames[i] for i in range(\n",
    "            frames.shape[0]) if i % self.frame_interval == 0])\n",
    "        rgb_frames = TF.resize(rgb_frames, size=self.resize)\n",
    "        # divide by 255 to map pixel values to interval [0,1]\n",
    "        rgb_frames = (rgb_frames/255).to(self.device)\n",
    "\n",
    "        # extract rgb_features\n",
    "        rgb_chunks = torch.split(rgb_frames, split_size_or_sections=self.batch_size, dim=0)\n",
    "        rgb_features = []\n",
    "\n",
    "        for chunk in rgb_chunks:\n",
    "            features = self.rgb_model(chunk)['flatten']\n",
    "            rgb_features.append(features)\n",
    "\n",
    "        # gc.collect(features, rgb_chunks, chunk)\n",
    "        rgb_features = torch.cat(rgb_features, dim=0).to('cpu')\n",
    "        rgb_features = rgb_features[1:]\n",
    "\n",
    "        # extract flow_features\n",
    "        flow_stack1, flow_stack2 = self.transforms(rgb_frames[:-1], rgb_frames[1:])\n",
    "        flow_stack1 = torch.split(flow_stack1, split_size_or_sections=self.batch_size, dim=0)\n",
    "        flow_stack2 = torch.split(flow_stack2, split_size_or_sections=self.batch_size, dim=0)\n",
    "\n",
    "        flow_features = []\n",
    "\n",
    "        for stack1, stack2 in zip(flow_stack1, flow_stack2):\n",
    "            features = self.flow_model(stack1, stack2)\n",
    "            # append last item from extracted flow_features, as it corresponds to last iteration (most accurate one)\n",
    "            features = flow_to_image(features[-1])\n",
    "            features = self.rgb_model(features/255)['flatten']\n",
    "            flow_features.append(features)\n",
    "\n",
    "        # gc.collect(features, stack1, stack2, flow_stack1, flow_stack2)\n",
    "        flow_features = torch.cat(flow_features, dim=0).to('cpu')\n",
    "\n",
    "        assert flow_features.shape == rgb_features.shape, f'shapes of rgb ({rgb_features.shape}) and flow ({flow_features.shape}) features do not match'\n",
    "\n",
    "        return rgb_features.detach().cpu().resolve_conj().resolve_neg().numpy(), flow_features.detach().cpu().resolve_conj().resolve_neg().numpy()\n",
    "\n",
    "    # '/workspace/pvc-meteor/downloads/Video XML Annotations'\n",
    "    def annotation_processor(self, video_name):\n",
    "        zip_name = video_name[:-4] + '.zip'\n",
    "        # check if name exist\n",
    "\n",
    "        if zip_name not in os.listdir(self.anno_zip_dir):\n",
    "            return None\n",
    "\n",
    "        else:\n",
    "            # load zip object\n",
    "            zip_file = ZipFile(os.path.join(self.anno_zip_dir, zip_name))\n",
    "            nr_frames = len([i for i in zip_file.namelist() if '.xml' in i])\n",
    "            nr_frames = np.floor(nr_frames / self.frame_interval).astype(int)\n",
    "            template = np.zeros((nr_frames, 7))\n",
    "\n",
    "            append_folder = 'Annotations/' in zip_file.namelist()\n",
    "            # iterate through key-frames\n",
    "            for i_temp, i_frame in enumerate([i * self.frame_interval for i in range(nr_frames)]):\n",
    "                frame_name = 'frame_{0:06d}.xml'.format(i_frame)\n",
    "                frame_name = 'Annotations/' + \\\n",
    "                    frame_name if append_folder else f'{zip_name[:-4]}/Annotations/' + frame_name\n",
    "\n",
    "                xml_file = xmltodict.parse(zip_file.read(frame_name))[\n",
    "                    'annotation']\n",
    "\n",
    "                if 'object' not in xml_file:\n",
    "                    # behave as if no file found\n",
    "                    return None\n",
    "\n",
    "                if not isinstance(xml_file['object'], list):\n",
    "                    xml_file['object'] = [xml_file['object']]\n",
    "\n",
    "                for obj in xml_file['object']:\n",
    "                    if obj['name'] != 'EgoVehicle':\n",
    "                        continue\n",
    "                    for attr in obj['attributes']['attribute']:\n",
    "                        if 'GPSData' in attr:\n",
    "                            continue\n",
    "                        if attr['name'] in self.labels:\n",
    "                            if attr['value'] in self.labels[attr['name']]:\n",
    "                                c_idx = self.labels_mapping[attr['name']]\n",
    "\n",
    "                                template[i_temp, c_idx] = 1\n",
    "        return template[1:]\n",
    "\n",
    "    def file_to_features(self, file_path):\n",
    "        video_file_name = file_path[-29:]\n",
    "        zip_file_name = video_file_name[:-4] + '.zip'\n",
    "\n",
    "        annotation = self.annotation_processor(zip_file_name)\n",
    "\n",
    "        # skip video if no annotations are available\n",
    "        if not isinstance(annotation, np.ndarray):\n",
    "            return None, None\n",
    "\n",
    "        else:\n",
    "            rgb_features, flow_features = self.video_processor(\n",
    "                os.path.join(self.vid_dir, video_file_name))\n",
    "\n",
    "        assert rgb_features.shape == flow_features.shape, 'rgb and flow features have different shape'\n",
    "        assert annotation.shape[0] == rgb_features.shape[0], f'annotations and image features have different length; anno_length = {annotation.shape[0]}, feature_length = {rgb_features.shape[0]}'\n",
    "\n",
    "        # create dictionary and write to pickle file\n",
    "        return {\n",
    "            video_file_name:\n",
    "                {\n",
    "                    'rgb': rgb_features,\n",
    "                    'flow': flow_features\n",
    "                }\n",
    "        }, {video_file_name: annotation}\n",
    "\n",
    "    def dir_to_features(self, save=True, use_mp=False):\n",
    "        if use_mp: \n",
    "            warnings.warn('using multiprocessing with cuda is currently not supported', category=UserWarning, stacklevel=2)\n",
    "            \n",
    "        # keep start time to differentiate between pickled files\n",
    "        start_time = datetime.now()\n",
    "        start_time = start_time.strftime(\"%d-%m-%Y-%H-%M\")\n",
    "\n",
    "        general_informaion = {\n",
    "            'fps': self.frame_interval, \n",
    "            'rgb_extractor': self.rgb_model.__class__.__name__,\n",
    "            'flow_extractor': self.flow_model.__class__.__name__, \n",
    "            'extraction_time': start_time\n",
    "            }\n",
    "\n",
    "        output_dict = {'meta': general_informaion,\n",
    "                       'features': dict(), \n",
    "                       'annotations': dict()\n",
    "                       }\n",
    "\n",
    "        if use_mp:\n",
    "            # pool = Pool(processes=cpu_count())\n",
    "\n",
    "            path_iterator = glob(self.vid_dir + '/*.MP4')\n",
    "\n",
    "            with Pool(processes=2) as p:\n",
    "                result_iterator = tqdm(p.imap_unordered(self.file_to_features, path_iterator), total=len(path_iterator), desc=\"Extracting features\")\n",
    "\n",
    "                p.close()\n",
    "                p.join()\n",
    "\n",
    "            for result in result_iterator:\n",
    "                vid_features, vid_annot = result\n",
    "                if vid_features == None:\n",
    "                    continue\n",
    "                output_dict['features'].update(vid_features)\n",
    "                output_dict['annotations'].update(vid_annot)\n",
    "\n",
    "        else:\n",
    "            for file_path in tqdm(glob(self.vid_dir + '/*.MP4')):\n",
    "                vid_features, vid_annot = self.file_to_features(file_path)\n",
    "\n",
    "                if vid_features == None:\n",
    "                    continue\n",
    "\n",
    "                output_dict['features'].update(vid_features)\n",
    "                output_dict['annotations'].update(vid_annot)\n",
    "\n",
    "        if save:\n",
    "            # create the file name using the start_time and extracted_features variables\n",
    "            file_name = 'extracted_features_{}.pkl'.format(start_time)\n",
    "\n",
    "            # open the file in write mode\n",
    "            with open(self.output_dir + file_name, 'wb') as file:\n",
    "                # use pickle to serialize the dictionary and write it to the file\n",
    "                pickle.dump(output_dict, file)\n",
    "\n",
    "        return output_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nprototype = FeatureExtractor(\\n    # METEOR Dataset has 30 FPS --> only taking every 30th frame means using only 1 frame every second.\\n    FPS=15,\\n    vid_dir='../data_sample/videos/',\\n    output_dir='../data_sample/output/',\\n    anno_zip_dir='../data_sample/annotations/'\\n)\\n\\n# prototype.video_processor('/workspace/persistent/data_sample/videos/REC_1970_01_01_07_40_16_F.MP4')\\n# prototype.annotation_processor2('REC_1970_01_01_07_40_16_F.zip', '/workspace/persistent/data sample/annotations/frame')\\nprototype.dir_to_features()\\n\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "prototype = FeatureExtractor(\n",
    "    # METEOR Dataset has 30 FPS --> only taking every 30th frame means using only 1 frame every second.\n",
    "    FPS=15,\n",
    "    vid_dir='../data_sample/videos/',\n",
    "    output_dir='../data_sample/output/',\n",
    "    anno_zip_dir='../data_sample/annotations/'\n",
    ")\n",
    "\n",
    "# prototype.video_processor('/workspace/persistent/data_sample/videos/REC_1970_01_01_07_40_16_F.MP4')\n",
    "# prototype.annotation_processor2('REC_1970_01_01_07_40_16_F.zip', '/workspace/persistent/data sample/annotations/frame')\n",
    "prototype.dir_to_features()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 8/1250 [07:44<21:49:01, 63.24s/it]"
     ]
    }
   ],
   "source": [
    "extractor = FeatureExtractor(FPS=15)\n",
    "\n",
    "extractor.dir_to_features()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.15 ('thesis')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "21e8d3179073958173d6cf46a62335ced4bd9060b16a08c7dd2ce09d931d915c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
